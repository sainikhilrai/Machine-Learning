{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreated on Wed Nov  8 16:00:03 2017\\n\\n@author: nikhil\\n\\nCode for the logistic regression:\\nThis code is the implementaion of logistice regression model for binary class classification.\\nIt uses the gradient descent method for finding the optimum parameter of our model.\\n\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python2\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Created on Wed Nov  8 16:00:03 2017\n",
    "\n",
    "@author: nikhil\n",
    "\n",
    "Code for the logistic regression:\n",
    "This code is the implementaion of logistice regression model for binary class classification.\n",
    "It uses the gradient descent method for finding the optimum parameter of our model.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from sklearn import metrics\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hypothesis function: It gives the probability of instances belonging to one class\n",
    "def hypothesisF(theata,x):\n",
    "    theataT = np.transpose(theata)\n",
    "    xT = np.transpose(x)\n",
    "    mul = np.matmul(theataT,xT)\n",
    "    probability = 1/(1 + np.exp(-mul))\n",
    "    return probability\n",
    "\n",
    "    \n",
    "#gradient descent method\n",
    "def gradientDescentMethod(learningR,toleranceV,theata,theataOld,X,y):\n",
    "    while (np.linalg.norm(theata - theataOld,ord = 2)) >= toleranceV:\n",
    "        theataOld = theata\n",
    "        theata = theataOld - learningR * ( np.matmul(X.T, (hypothesisF(theata,X) - y)))\n",
    "    return theata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load train and test data\n",
    "dataTrain = loadmat('mnistTrainImages.mat')\n",
    "trainLabel =loadmat('mnistTrainLabels.mat')\n",
    "dataTest =loadmat('mnistTestImages.mat')\n",
    "testLabel =loadmat('mnistTestLabels.mat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#random initialization\n",
    "theata= np.ones(785)\n",
    "theataOld= theata * 1000\n",
    "learningRate= 0.1\n",
    "errorTolerance= 15 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#trainData and TestData\n",
    "X_train = dataTrain['trainData']            #here 'trainData' is an index of dictionary.\n",
    "X_train = np.insert(X_train,0,1,axis=1)     #adding ones to add the bias term\n",
    "y_trainLabel = trainLabel['trainLabels']    #here 'trainLabels' is an index of dictionary.\n",
    "X_test = dataTest['testData']               #here 'testData' is an index of dictionary.\n",
    "X_test = np.insert(X_test,0,1,axis=1)       #adding ones to add the bias term\n",
    "y_testLabel = testLabel['testLabels'] \n",
    "newyTL = [i[0] for i in y_trainLabel]\n",
    "newyTL = np.array(newyTL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikhil/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#calculate optimum threshold using the gradient Descent Method\n",
    "optimumTheata = gradientDescentMethod(0.1,15,theata,theataOld,X_train,newyTL)\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#threshold Value\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikhil/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Test Classifier with test data\n",
    "prediction = hypothesisF(optimumTheata,X_test)\n",
    "\n",
    "#comparing with the threshold\n",
    "for i in range(y_testLabel.size):\n",
    "    if(prediction[i]>threshold):\n",
    "        prediction[i] = 1\n",
    "    else:\n",
    "        prediction[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9911\n"
     ]
    }
   ],
   "source": [
    "#calculate accuracy\n",
    "correct = 0\n",
    "for i in range(y_testLabel.size):\n",
    "    if(prediction[i] == y_testLabel[i] ):\n",
    "        correct += 1\n",
    "accuracy = correct/float(y_testLabel.size)\n",
    "print \"Accuracy:\", accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

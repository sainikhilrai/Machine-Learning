{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreated on Wed Nov  8 16:00:03 2017\\n\\n@author: nikhil\\n\\nCode for the logistic regression:\\nThis code is the implementaion of logistice regression model for k-class classification.\\nIt uses the gradient descent method for finding the optimum parameter of our model.\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python2\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Created on Wed Nov  8 16:00:03 2017\n",
    "\n",
    "@author: nikhil\n",
    "\n",
    "Code for the logistic regression:\n",
    "This code is the implementaion of logistice regression model for k-class classification.\n",
    "It uses the gradient descent method for finding the optimum parameters of our model.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import copy\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from sklearn import metrics\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hypothesis function: It gives the probability of instances belonging to one class\n",
    "def hypothesisF(theata,x):\n",
    "    theataT = np.transpose(theata)\n",
    "    xT = np.transpose(x)\n",
    "    mul = np.matmul(theataT,xT)\n",
    "    probability = 1/(1 + np.exp(-mul))\n",
    "    return probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gradient descent method\n",
    "def gradientDescentMethod(learningR,toleranceV,theata,theataOld,X,y):\n",
    "    while (np.linalg.norm(theata - theataOld,ord = 2)) >= toleranceV:\n",
    "        theataOld = theata\n",
    "        theata = theataOld - learningR * ( np.matmul(X.T, (hypothesisF(theata,X) - y)))\n",
    "    return theata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#trainLabe function\n",
    "def makeTrain(newyTL,index):\n",
    "    trainLabel= copy.deepcopy(newyTL) \n",
    "    for i in range(newyTL.size):\n",
    "        if(newyTL[i] == index):\n",
    "            trainLabel[i] = 1\n",
    "        else:\n",
    "            trainLabel[i] = 0\n",
    "    return trainLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fucntion for finding maximum index\n",
    "def maxProbability(prediction):\n",
    "    maxpred= []\n",
    "    i = 0\n",
    "    for j in range(10000):\n",
    "        maxV = max(predA[i][j],predA[i+1][j],predA[i+2][j],predA[i+3][j],predA[i+4][j],predA[i+5][j],predA[i+6][j],predA[i+7][j],predA[i+8][j],predA[i+9][j])\n",
    "        if ( maxV == predA[i][j]):\n",
    "            maxpred.append(i)\n",
    "        elif(maxV == predA[i+1][j]):\n",
    "            maxpred.append(i+1)\n",
    "        elif(maxV == predA[i+2][j]):\n",
    "            maxpred.append(i+2)\n",
    "        elif(maxV == predA[i+3][j]):\n",
    "            maxpred.append(i+3)\n",
    "        elif(maxV == predA[i+4][j]):\n",
    "            maxpred.append(i+4)\n",
    "        elif(maxV == predA[i+5][j]):\n",
    "            maxpred.append(i+5)\n",
    "        elif(maxV == predA[i+6][j]):\n",
    "            maxpred.append(i+6)\n",
    "        elif(maxV == predA[i+7][j]):\n",
    "            maxpred.append(i+7)\n",
    "        elif(maxV == predA[i+8][j]):\n",
    "            maxpred.append(i+8)\n",
    "        else:\n",
    "            maxpred.append(i+9)\n",
    "    return maxpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load training and testing data\n",
    "dataTrain = loadmat('TrainImages.mat')\n",
    "trainLabel =loadmat('TrainLabels.mat')\n",
    "dataTest =loadmat('TestImages.mat')\n",
    "testLabel =loadmat('TestLabels.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#random initialization\n",
    "theata= np.ones(785)\n",
    "theataOld= theata * 10000\n",
    "learningRate= 0.01\n",
    "errorTolerance= 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainData and TestData\n",
    "X_train = dataTrain['trainData']              #here 'trainData' is an index of dictionary.\n",
    "X_train = np.insert(X_train,0,1,axis=1)       #adding ones to add the bias term\n",
    "y_trainLabel = trainLabel['trainLabels']      #here 'trainLabels' is an index of dictionary.\n",
    "X_test = dataTest['testData']                 #here 'testData' is an index of dictionary.\n",
    "X_test = np.insert(X_test,0,1,axis=1)         #adding ones to add the bias term\n",
    "y_testLabel = testLabel['testLabels'] \n",
    "newyTL = [i[0] for i in y_trainLabel]\n",
    "newyTL = np.array(newyTL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make suitable changes in train data for k-classifier\n",
    "trainDataList = []\n",
    "for i in range(10):\n",
    "    trainDataList.append(makeTrain(newyTL,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikhil/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#calculate optimum threshold using gradient Descent Method\n",
    "optTheata = []\n",
    "for i in range(10):\n",
    "    optTheata.append(gradientDescentMethod(learningRate,errorTolerance,theata,theataOld,X_train,trainDataList[i]));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikhil/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Test Classifier with test data\n",
    "predA = []\n",
    "for i in range(10):\n",
    "    predA.append(hypothesisF(optTheata[i],X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#find the maximum probability for deciding the class of test data\n",
    "prediction= maxProbability(predA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8345\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "correct = 0\n",
    "for i in range(y_testLabel.size):\n",
    "    if(prediction[i] == y_testLabel[i] ):\n",
    "        correct += 1\n",
    "accuracy = correct/float(y_testLabel.size)\n",
    "print \"Accuracy:\", accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
